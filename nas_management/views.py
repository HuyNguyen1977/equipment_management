from django.shortcuts import render, redirect, get_object_or_404
from django.contrib import messages
from django.contrib.auth.decorators import login_required
from django.contrib.admin.views.decorators import staff_member_required
from django.core.paginator import Paginator
from django.http import JsonResponse, HttpResponse, FileResponse
from django.utils import timezone
from django.db.models import Q, Count
from django.views.decorators.http import require_http_methods
from django.urls import reverse
from datetime import datetime, timedelta
import json
import csv
import io

from .models import NASConfig, LoginHistory, SystemStats, NASLog, FileOperation
from .synology_api import SynologyAPIClient, SynologyAPIError


@staff_member_required
def nas_dashboard(request):
    """Dashboard theo d√µi CPU/RAM/Disk"""
    nas_list = NASConfig.objects.filter(is_active=True)
    
    # L·∫•y NAS ƒë∆∞·ª£c ch·ªçn ho·∫∑c NAS ƒë·∫ßu ti√™n
    nas_id = request.GET.get('nas_id')
    selected_nas = None
    stats_data = None
    recent_stats = None
    
    if nas_id:
        selected_nas = get_object_or_404(NASConfig, id=nas_id, is_active=True)
    elif nas_list.exists():
        selected_nas = nas_list.first()
    
    if selected_nas:
        try:
            with SynologyAPIClient(selected_nas) as client:
                # L·∫•y th√¥ng tin CPU v√† Memory
                cpu_info = client.get_cpu_info()
                memory_info = client.get_memory_info()
                disk_info = client.get_disk_info()
                
                # T√≠nh to√°n stats
                cpu_usage = cpu_info.get('cpu', {}).get('system_load', 0)
                memory_data = cpu_info.get('memory', {})
                memory_total = memory_data.get('total', 0)
                memory_used = memory_data.get('real_usage', 0)
                memory_usage = (memory_used / memory_total * 100) if memory_total > 0 else 0
                
                stats_data = {
                    'cpu_usage': round(cpu_usage, 2),
                    'memory_usage': round(memory_usage, 2),
                    'memory_total': memory_total,
                    'memory_used': memory_used,
                    'memory_free': memory_total - memory_used,
                    'disk_info': disk_info,
                }
                
                # L∆∞u v√†o database
                SystemStats.objects.create(
                    nas=selected_nas,
                    cpu_usage=cpu_usage,
                    memory_usage=memory_usage,
                    memory_total=memory_total,
                    memory_used=memory_used,
                    disk_usage=disk_info,
                )
                
        except SynologyAPIError as e:
            messages.error(request, f"L·ªói k·∫øt n·ªëi NAS: {str(e)}")
        except Exception as e:
            messages.error(request, f"L·ªói: {str(e)}")
        
        # L·∫•y stats g·∫ßn ƒë√¢y ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì
        recent_stats = SystemStats.objects.filter(
            nas=selected_nas
        ).order_by('-timestamp')[:60]  # 60 ƒëi·ªÉm g·∫ßn nh·∫•t
    
    context = {
        'nas_list': nas_list,
        'selected_nas': selected_nas,
        'stats_data': stats_data,
        'recent_stats': recent_stats,
    }
    return render(request, 'nas_management/dashboard.html', context)


@staff_member_required
def login_history(request):
    """Xem l·ªãch s·ª≠ ƒëƒÉng nh·∫≠p"""
    nas_list = NASConfig.objects.filter(is_active=True)
    
    # Filter
    nas_id = request.GET.get('nas_id')
    username = request.GET.get('username', '').strip()
    is_success = request.GET.get('is_success')
    date_from = request.GET.get('date_from')
    date_to = request.GET.get('date_to')
    
    login_history = LoginHistory.objects.all()
    
    if nas_id:
        login_history = login_history.filter(nas_id=nas_id)
    
    if username:
        login_history = login_history.filter(username__icontains=username)
    
    if is_success:
        login_history = login_history.filter(is_success=(is_success == '1'))
    
    if date_from:
        try:
            date_from_obj = datetime.strptime(date_from, '%Y-%m-%d')
            login_history = login_history.filter(login_time__gte=date_from_obj)
        except:
            pass
    
    if date_to:
        try:
            date_to_obj = datetime.strptime(date_to, '%Y-%m-%d') + timedelta(days=1)
            login_history = login_history.filter(login_time__lt=date_to_obj)
        except:
            pass
    
    # Ph√¢n trang
    paginator = Paginator(login_history.order_by('-login_time'), 50)
    page_number = request.GET.get('page')
    page_obj = paginator.get_page(page_number)
    
    # Th·ªëng k√™ login failures
    failure_stats = LoginHistory.objects.filter(
        is_success=False
    ).values('ip_address').annotate(
        count=Count('id')
    ).order_by('-count')[:10]
    
    context = {
        'nas_list': nas_list,
        'page_obj': page_obj,
        'login_history': page_obj,
        'failure_stats': failure_stats,
        'selected_nas_id': nas_id,
        'username_filter': username,
        'is_success_filter': is_success,
        'date_from': date_from,
        'date_to': date_to,
    }
    return render(request, 'nas_management/login_history.html', context)


@staff_member_required
def sync_login_history(request, nas_id):
    """ƒê·ªìng b·ªô l·ªãch s·ª≠ ƒëƒÉng nh·∫≠p t·ª´ NAS"""
    nas = get_object_or_404(NASConfig, id=nas_id, is_active=True)
    
    try:
        with SynologyAPIClient(nas) as client:
            login_logs = client.get_login_history(limit=500)
            
            count = 0
            for log in login_logs:
                username = log.get('user', '')
                ip_address = log.get('ip', '')
                login_time_str = log.get('time', '')
                is_success = log.get('result', '') == 'success'
                failure_reason = log.get('reason', '') if not is_success else ''
                
                # Parse time
                try:
                    login_time = datetime.fromtimestamp(int(login_time_str))
                except:
                    continue
                
                # T·∫°o ho·∫∑c c·∫≠p nh·∫≠t
                LoginHistory.objects.update_or_create(
                    nas=nas,
                    username=username,
                    ip_address=ip_address,
                    login_time=login_time,
                    defaults={
                        'is_success': is_success,
                        'failure_reason': failure_reason,
                        'user_agent': log.get('user_agent', ''),
                    }
                )
                count += 1
            
            messages.success(request, f'ƒê√£ ƒë·ªìng b·ªô {count} b·∫£n ghi ƒëƒÉng nh·∫≠p t·ª´ {nas.name}')
            
    except SynologyAPIError as e:
        messages.error(request, f"L·ªói: {str(e)}")
    except Exception as e:
        messages.error(request, f"L·ªói: {str(e)}")
    
    return redirect('nas_management:login_history')


def _get_logs_dashboard_data(request, log_type):
    """Helper function ƒë·ªÉ l·∫•y d·ªØ li·ªáu dashboard cho t·ª´ng lo·∫°i log"""
    nas_list = NASConfig.objects.filter(is_active=True)
    
    # Filter
    nas_id = request.GET.get('nas_id')
    date_from = request.GET.get('date_from')
    date_to = request.GET.get('date_to')
    
    # M·∫∑c ƒë·ªãnh l·∫•y 30 ng√†y g·∫ßn nh·∫•t
    if not date_to:
        date_to = timezone.now().date()
    if not date_from:
        date_from = (timezone.now() - timedelta(days=30)).date()
    
    logs = NASLog.objects.filter(log_type=log_type)
    
    if nas_id:
        logs = logs.filter(nas_id=nas_id)
        selected_nas = get_object_or_404(NASConfig, id=nas_id, is_active=True)
    else:
        selected_nas = None
    
    # Filter theo ng√†y
    if date_from:
        try:
            date_from_obj = datetime.strptime(str(date_from), '%Y-%m-%d')
            if timezone.is_naive(date_from_obj):
                date_from_obj = timezone.make_aware(date_from_obj)
            logs = logs.filter(timestamp__gte=date_from_obj)
        except:
            pass
    
    if date_to:
        try:
            date_to_obj = datetime.strptime(str(date_to), '%Y-%m-%d') + timedelta(days=1)
            if timezone.is_naive(date_to_obj):
                date_to_obj = timezone.make_aware(date_to_obj)
            logs = logs.filter(timestamp__lt=date_to_obj)
        except:
            pass
    
    # Th·ªëng k√™ t·ªïng quan
    total_logs = logs.count()
    logs_by_level = logs.values('level').annotate(count=Count('id')).order_by('level')
    logs_by_nas = logs.values('nas__name').annotate(count=Count('id')).order_by('-count')
    logs_by_category = logs.values('category').annotate(count=Count('id')).order_by('-count')[:10]
    logs_by_source = logs.values('source').annotate(count=Count('id')).order_by('-count')[:10]
    
    # Th·ªëng k√™ theo ng√†y (30 ng√†y g·∫ßn nh·∫•t)
    daily_stats = []
    for i in range(30):
        day = (timezone.now() - timedelta(days=29-i)).date()
        day_start = timezone.make_aware(datetime.combine(day, datetime.min.time()))
        day_end = day_start + timedelta(days=1)
        day_logs = logs.filter(timestamp__gte=day_start, timestamp__lt=day_end)
        daily_stats.append({
            'date': day,
            'total': day_logs.count(),
            'info': day_logs.filter(level='info').count(),
            'warning': day_logs.filter(level='warning').count(),
            'error': day_logs.filter(level='error').count(),
            'critical': day_logs.filter(level='critical').count(),
        })
    
    # Logs g·∫ßn ƒë√¢y
    recent_logs = logs.order_by('-timestamp')[:20]
    
    # T·ªïng h·ª£p theo level
    level_stats = {
        'info': logs.filter(level='info').count(),
        'warning': logs.filter(level='warning').count(),
        'error': logs.filter(level='error').count(),
        'critical': logs.filter(level='critical').count(),
    }
    
    # Th·ªëng k√™ ƒë·∫∑c bi·ªát cho filexferlog
    filexfer_stats = None
    if log_type == 'filexferlog':
        filexfer_stats = {
            'by_operation': logs.values('operation').annotate(count=Count('id')).order_by('-count')[:10],
            'by_user': logs.values('source').annotate(count=Count('id')).order_by('-count')[:10],
            'top_files': logs.exclude(file_path='').values('file_path').annotate(count=Count('id')).order_by('-count')[:10],
        }
    elif log_type == 'connectlog':
        # Th·ªëng k√™ ƒë·∫∑c bi·ªát cho connectlog
        filexfer_stats = {
            'by_user': logs.values('source').annotate(count=Count('id')).order_by('-count')[:10],
            'by_category': logs.values('category').annotate(count=Count('id')).order_by('-count')[:10],
        }
    
    return {
        'nas_list': nas_list,
        'selected_nas': selected_nas,
        'selected_nas_id': str(nas_id) if nas_id else '',
        'date_from': str(date_from) if date_from else '',
        'date_to': str(date_to) if date_to else '',
        'log_type': log_type,
        'total_logs': total_logs,
        'level_stats': level_stats,
        'logs_by_level': logs_by_level,
        'logs_by_nas': logs_by_nas,
        'logs_by_category': logs_by_category,
        'logs_by_source': logs_by_source,
        'daily_stats': daily_stats,
        'recent_logs': recent_logs,
        'filexfer_stats': filexfer_stats,
    }


@staff_member_required
def syslog_dashboard(request):
    """Dashboard th·ªëng k√™ System Logs"""
    context = _get_logs_dashboard_data(request, 'syslog')
    context['log_type_display'] = 'System Logs'
    return render(request, 'nas_management/logs_dashboard.html', context)


@staff_member_required
def connectlog_dashboard(request):
    """Dashboard th·ªëng k√™ Connection Logs"""
    context = _get_logs_dashboard_data(request, 'connectlog')
    context['log_type_display'] = 'Connection Logs'
    return render(request, 'nas_management/logs_dashboard.html', context)


@staff_member_required
def filexferlog_dashboard(request):
    """Dashboard th·ªëng k√™ File Transfer Logs"""
    context = _get_logs_dashboard_data(request, 'filexferlog')
    context['log_type_display'] = 'File Transfer Logs'
    return render(request, 'nas_management/logs_dashboard.html', context)


@staff_member_required
def logs_dashboard(request):
    """Dashboard th·ªëng k√™ logs NAS - t·ªïng h·ª£p t·∫•t c·∫£"""
    nas_list = NASConfig.objects.filter(is_active=True)
    
    # Filter
    nas_id = request.GET.get('nas_id')
    date_from = request.GET.get('date_from')
    date_to = request.GET.get('date_to')
    
    # M·∫∑c ƒë·ªãnh l·∫•y 30 ng√†y g·∫ßn nh·∫•t
    if not date_to:
        date_to = timezone.now().date()
    if not date_from:
        date_from = (timezone.now() - timedelta(days=30)).date()
    
    logs = NASLog.objects.all()
    
    if nas_id:
        logs = logs.filter(nas_id=nas_id)
        selected_nas = get_object_or_404(NASConfig, id=nas_id, is_active=True)
    else:
        selected_nas = None
    
    # Filter theo ng√†y
    if date_from:
        try:
            date_from_obj = datetime.strptime(str(date_from), '%Y-%m-%d')
            if timezone.is_naive(date_from_obj):
                date_from_obj = timezone.make_aware(date_from_obj)
            logs = logs.filter(timestamp__gte=date_from_obj)
        except:
            pass
    
    if date_to:
        try:
            date_to_obj = datetime.strptime(str(date_to), '%Y-%m-%d') + timedelta(days=1)
            if timezone.is_naive(date_to_obj):
                date_to_obj = timezone.make_aware(date_to_obj)
            logs = logs.filter(timestamp__lt=date_to_obj)
        except:
            pass
    
    # Th·ªëng k√™ theo lo·∫°i log
    logs_by_type = logs.values('log_type').annotate(count=Count('id')).order_by('log_type')
    
    # Th·ªëng k√™ t·ªïng quan
    total_logs = logs.count()
    level_stats = {
        'info': logs.filter(level='info').count(),
        'warning': logs.filter(level='warning').count(),
        'error': logs.filter(level='error').count(),
        'critical': logs.filter(level='critical').count(),
    }
    
    # Th·ªëng k√™ theo ng√†y (30 ng√†y g·∫ßn nh·∫•t)
    daily_stats = []
    for i in range(30):
        day = (timezone.now() - timedelta(days=29-i)).date()
        day_start = timezone.make_aware(datetime.combine(day, datetime.min.time()))
        day_end = day_start + timedelta(days=1)
        day_logs = logs.filter(timestamp__gte=day_start, timestamp__lt=day_end)
        daily_stats.append({
            'date': day,
            'total': day_logs.count(),
            'syslog': day_logs.filter(log_type='syslog').count(),
            'connectlog': day_logs.filter(log_type='connectlog').count(),
            'filexferlog': day_logs.filter(log_type='filexferlog').count(),
        })
    
    context = {
        'nas_list': nas_list,
        'selected_nas': selected_nas,
        'selected_nas_id': str(nas_id) if nas_id else '',
        'date_from': str(date_from) if date_from else '',
        'date_to': str(date_to) if date_to else '',
        'total_logs': total_logs,
        'level_stats': level_stats,
        'logs_by_type': logs_by_type,
        'daily_stats': daily_stats,
        'log_type': None,  # T·ªïng h·ª£p
        'log_type_display': 'All Logs',
    }
    return render(request, 'nas_management/logs_dashboard.html', context)


@staff_member_required
def nas_logs(request):
    """Xem logs c·ªßa NAS"""
    nas_list = NASConfig.objects.filter(is_active=True)
    
    # Filter
    nas_id = request.GET.get('nas_id')
    log_type = request.GET.get('log_type')
    level = request.GET.get('level')
    category = request.GET.get('category', '').strip()
    date_from = request.GET.get('date_from')
    date_to = request.GET.get('date_to')
    
    logs = NASLog.objects.all()
    
    if nas_id:
        logs = logs.filter(nas_id=nas_id)
    
    if log_type:
        logs = logs.filter(log_type=log_type)
    
    if level:
        logs = logs.filter(level=level)
    
    if category:
        logs = logs.filter(category__icontains=category)
    
    if date_from:
        try:
            date_from_obj = datetime.strptime(date_from, '%Y-%m-%d')
            logs = logs.filter(timestamp__gte=date_from_obj)
        except:
            pass
    
    if date_to:
        try:
            date_to_obj = datetime.strptime(date_to, '%Y-%m-%d') + timedelta(days=1)
            logs = logs.filter(timestamp__lt=date_to_obj)
        except:
            pass
    
    # Ph√¢n trang
    paginator = Paginator(logs.order_by('-timestamp'), 100)
    page_number = request.GET.get('page')
    page_obj = paginator.get_page(page_number)
    
    from .forms import LogCSVUploadForm
    upload_form = LogCSVUploadForm()
    
    context = {
        'nas_list': nas_list,
        'page_obj': page_obj,
        'logs': page_obj,
        'selected_nas_id': str(nas_id) if nas_id else '',
        'log_type_filter': log_type or '',
        'level_filter': level or '',
        'category_filter': category or '',
        'date_from': date_from or '',
        'date_to': date_to or '',
        'upload_form': upload_form,
    }
    return render(request, 'nas_management/logs.html', context)


@staff_member_required
def sync_logs(request, nas_id):
    """ƒê·ªìng b·ªô logs t·ª´ NAS"""
    nas = get_object_or_404(NASConfig, id=nas_id, is_active=True)
    
    try:
        with SynologyAPIClient(nas) as client:
            # Th·ª≠ l·∫•y logs v·ªõi limit l·ªõn h∆°n
            nas_logs = client.get_logs(limit=1000)
            
            # Debug: log s·ªë l∆∞·ª£ng logs nh·∫≠n ƒë∆∞·ª£c
            import logging
            logger = logging.getLogger('nas_management')
            logger.info(f"Received {len(nas_logs)} logs from {nas.name}")
            
            if not nas_logs:
                # Th·ª≠ ki·ªÉm tra xem c√≥ th·ªÉ k·∫øt n·ªëi ƒë∆∞·ª£c kh√¥ng v√† API n√†o c√≥ s·∫µn
                try:
                    # Test m·ªôt API ƒë∆°n gi·∫£n ƒë·ªÉ xem c√≥ k·∫øt n·ªëi ƒë∆∞·ª£c kh√¥ng
                    test_info = client.get_system_info()
                    logger.info(f"System info retrieved: {test_info}")
                    
                    # Ki·ªÉm tra API info
                    eventlog_info = client.get_api_info('SYNO.Core.EventLog')
                    has_eventlog_api = bool(eventlog_info)
                    
                    # L·∫•y danh s√°ch t·∫•t c·∫£ API ƒë·ªÉ debug
                    all_apis = client.list_all_apis()
                    log_related_apis = [api for api in all_apis.keys() if 'log' in api.lower() or 'event' in api.lower()]
                    
                    if not has_eventlog_api:
                        error_msg = (
                            f'Kh√¥ng t√¨m th·∫•y API SYNO.Core.EventLog t·ª´ {nas.name}.\n\n'
                            f'‚ö†Ô∏è Log Center package c√≥ th·ªÉ ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t ho·∫∑c ch∆∞a ƒë∆∞·ª£c k√≠ch ho·∫°t tr√™n NAS.\n\n'
                            f'üìã H∆∞·ªõng d·∫´n:\n'
                            f'1. ƒêƒÉng nh·∫≠p v√†o DSM c·ªßa NAS\n'
                            f'2. V√†o Package Center\n'
                            f'3. T√¨m v√† c√†i ƒë·∫∑t "Log Center"\n'
                            f'4. Sau khi c√†i ƒë·∫∑t, m·ªü Log Center v√† k√≠ch ho·∫°t\n'
                            f'5. ƒê·∫£m b·∫£o user "{nas.username}" c√≥ quy·ªÅn truy c·∫≠p Log Center\n\n'
                        )
                        if log_related_apis:
                            error_msg += f'üìå C√°c API li√™n quan ƒë·∫øn log t√¨m th·∫•y: {", ".join(log_related_apis[:5])}\n\n'
                        error_msg += f'Ho·∫∑c ch·∫°y command ƒë·ªÉ ki·ªÉm tra chi ti·∫øt:\n'
                        error_msg += f'python manage.py test_nas_logs --nas-id {nas_id}'
                    else:
                        error_msg = (
                            f'Kh√¥ng t√¨m th·∫•y log n√†o t·ª´ {nas.name}.\n\n'
                            f'C√≥ th·ªÉ:\n'
                            f'1. NAS kh√¥ng c√≥ log n√†o trong th·ªùi gian n√†y\n'
                            f'2. User "{nas.username}" kh√¥ng c√≥ quy·ªÅn truy c·∫≠p logs\n'
                            f'3. Log Center ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh ƒë·ªÉ thu th·∫≠p logs\n\n'
                            f'Vui l√≤ng ki·ªÉm tra Log Center tr√™n NAS ho·∫∑c ch·∫°y command:\n'
                            f'python manage.py test_nas_logs --nas-id {nas_id}'
                        )
                except Exception as e:
                    error_msg = (
                        f'Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn NAS {nas.name}: {str(e)}\n\n'
                        f'Vui l√≤ng ki·ªÉm tra:\n'
                        f'1. NAS c√≥ ƒëang ho·∫°t ƒë·ªông kh√¥ng\n'
                        f'2. Th√¥ng tin ƒëƒÉng nh·∫≠p c√≥ ƒë√∫ng kh√¥ng\n'
                        f'3. Firewall c√≥ ch·∫∑n k·∫øt n·ªëi kh√¥ng'
                    )
                
                messages.warning(request, error_msg)
                # Gi·ªØ l·∫°i filter khi redirect
                redirect_url = reverse('nas_management:nas_logs')
                if nas_id:
                    redirect_url += f'?nas_id={nas_id}'
                return redirect(redirect_url)
            
            count = 0
            errors = []
            skipped_invalid = 0
            skipped_short = 0
            
            for log_entry in nas_logs:
                try:
                    # X·ª≠ l√Ω level - normalize v·ªÅ lowercase
                    level_raw = log_entry.get('level', 'info')
                    level = level_raw.lower() if isinstance(level_raw, str) else 'info'
                    if level not in ['info', 'warning', 'error', 'critical']:
                        level = 'info'
                    
                    # X·ª≠ l√Ω category
                    category = log_entry.get('category', '') or log_entry.get('program', '') or ''
                    
                    # X·ª≠ l√Ω message
                    message = log_entry.get('message', '') or log_entry.get('msg', '') or log_entry.get('content', '') or str(log_entry)
                    
                    # X·ª≠ l√Ω source
                    source = log_entry.get('source', '') or log_entry.get('host_name', '') or log_entry.get('module', '') or log_entry.get('program', '') or ''
                    
                    # X·ª≠ l√Ω timestamp
                    timestamp_str = log_entry.get('time', '') or log_entry.get('timestamp', '')
                    timestamp = None
                    
                    if timestamp_str:
                        try:
                            # C√≥ th·ªÉ l√† Unix timestamp (s·ªë) ho·∫∑c string
                            if isinstance(timestamp_str, (int, float)):
                                timestamp = datetime.fromtimestamp(timestamp_str)
                            elif isinstance(timestamp_str, str) and timestamp_str.isdigit():
                                timestamp = datetime.fromtimestamp(int(timestamp_str))
                            else:
                                # Th·ª≠ parse t·ª´ datetime string (nhi·ªÅu format kh√°c nhau)
                                for fmt in ['%Y-%m-%d %H:%M:%S', '%Y/%m/%d %H:%M:%S', '%d/%m/%Y %H:%M:%S', '%Y-%m-%dT%H:%M:%S']:
                                    try:
                                        timestamp = datetime.strptime(str(timestamp_str), fmt)
                                        break
                                    except:
                                        continue
                                if not timestamp:
                                    timestamp = timezone.now()
                        except (ValueError, TypeError) as e:
                            timestamp = timezone.now()
                    else:
                        timestamp = timezone.now()
                    
                    # ƒê·∫£m b·∫£o timestamp c√≥ timezone
                    if timezone.is_naive(timestamp):
                        timestamp = timezone.make_aware(timestamp)
                    
                    # Ki·ªÉm tra xem ƒë√¢y c√≥ ph·∫£i l√† log entry h·ª£p l·ªá kh√¥ng
                    # B·ªè qua c√°c response l·ªói API (ch·ª©a JSON error)
                    message_lower = message.lower() if message else ''
                    if any(indicator in message_lower for indicator in ['{"error":', '"success":false', '"code":', 'api error']):
                        skipped_invalid += 1
                        logger.debug(f"Skipping invalid log entry (API error response): {message[:100]}")
                        continue
                    
                    # Ki·ªÉm tra message kh√¥ng ƒë∆∞·ª£c qu√° ng·∫Øn ho·∫∑c ch·ªâ l√† JSON r·ªóng
                    if len(message.strip()) < 5:
                        skipped_short += 1
                        continue
                    
                    # T·∫°o unique key ƒë·ªÉ tr√°nh duplicate
                    # S·ª≠ d·ª•ng nas + timestamp + message ƒë·ªÉ t·∫°o unique
                    # Gi·ªõi h·∫°n ƒë·ªô d√†i ƒë·ªÉ tr√°nh l·ªói database
                    message_short = message[:500] if message else ''
                    category_short = category[:100] if category else ''
                    source_short = source[:200] if source else ''
                    
                    NASLog.objects.update_or_create(
                        nas=nas,
                        timestamp=timestamp,
                        message=message_short,
                        defaults={
                            'level': level,
                            'category': category_short,
                            'source': source_short,
                        }
                    )
                    count += 1
                except Exception as e:
                    errors.append(f"Entry error: {str(e)}")
                    logger.error(f"Error processing log entry: {str(e)}, Entry: {log_entry}")
                    continue
            
            # Th√¥ng b√°o k·∫øt qu·∫£ chi ti·∫øt
            if count > 0:
                messages.success(request, f'ƒê√£ ƒë·ªìng b·ªô {count} log t·ª´ {nas.name}')
                if skipped_invalid > 0 or skipped_short > 0:
                    skip_msg = []
                    if skipped_invalid > 0:
                        skip_msg.append(f'{skipped_invalid} log kh√¥ng h·ª£p l·ªá (API error)')
                    if skipped_short > 0:
                        skip_msg.append(f'{skipped_short} log qu√° ng·∫Øn')
                    if skip_msg:
                        messages.info(request, f'ƒê√£ b·ªè qua: {", ".join(skip_msg)}')
            else:
                # Th√¥ng b√°o chi ti·∫øt h∆°n khi kh√¥ng c√≥ log n√†o ƒë∆∞·ª£c l∆∞u
                detail_msg = f'Kh√¥ng th·ªÉ ƒë·ªìng b·ªô log t·ª´ {nas.name}.\n\n'
                if len(nas_logs) > 0:
                    detail_msg += f'ƒê√£ nh·∫≠n ƒë∆∞·ª£c {len(nas_logs)} log entries nh∆∞ng:\n'
                    if skipped_invalid > 0:
                        detail_msg += f'- {skipped_invalid} log kh√¥ng h·ª£p l·ªá (ch·ª©a JSON error response)\n'
                    if skipped_short > 0:
                        detail_msg += f'- {skipped_short} log qu√° ng·∫Øn\n'
                    if len(errors) > 0:
                        detail_msg += f'- {len(errors)} log g·∫∑p l·ªói khi x·ª≠ l√Ω\n'
                    detail_msg += '\nC√≥ th·ªÉ format d·ªØ li·ªáu t·ª´ NAS kh√¥ng ƒë√∫ng ho·∫∑c c·∫ßn c·∫•u h√¨nh l·∫°i.'
                else:
                    detail_msg += 'Kh√¥ng nh·∫≠n ƒë∆∞·ª£c log n√†o t·ª´ NAS. Vui l√≤ng ki·ªÉm tra:\n'
                    detail_msg += '1. NAS c√≥ ƒëang t·∫°o logs kh√¥ng\n'
                    detail_msg += '2. User c√≥ quy·ªÅn truy c·∫≠p logs kh√¥ng\n'
                    detail_msg += '3. Log Center c√≥ ƒë∆∞·ª£c c√†i ƒë·∫∑t v√† k√≠ch ho·∫°t kh√¥ng'
                
                messages.warning(request, detail_msg)
            
            if errors:
                messages.warning(request, f'C√≥ {len(errors)} l·ªói khi x·ª≠ l√Ω logs. ƒê√£ ƒë·ªìng b·ªô ƒë∆∞·ª£c {count} log.')
            
    except SynologyAPIError as e:
        messages.error(request, f"L·ªói API: {str(e)}")
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        messages.error(request, f"L·ªói: {str(e)}")
        # Log chi ti·∫øt l·ªói ƒë·ªÉ debug
        import logging
        logger = logging.getLogger('nas_management')
        logger.error(f"Error syncing logs: {error_detail}")
    
    # Gi·ªØ l·∫°i filter khi redirect
    redirect_url = reverse('nas_management:nas_logs')
    if nas_id:
        redirect_url += f'?nas_id={nas_id}'
    return redirect(redirect_url)


@staff_member_required
def upload_logs_csv(request):
    """Upload v√† import logs t·ª´ file CSV export t·ª´ NAS - h·ªó tr·ª£ 3 lo·∫°i: syslog, connectlog, filexferlog"""
    from .forms import LogCSVUploadForm
    from django.db import IntegrityError
    
    if request.method == 'POST':
        form = LogCSVUploadForm(request.POST, request.FILES)
        if form.is_valid():
            nas = form.cleaned_data['nas']
            csv_file = form.cleaned_data['csv_file']
            
            try:
                # ƒê·ªçc file CSV
                if csv_file.name.endswith('.csv'):
                    # Detect lo·∫°i log t·ª´ filename
                    filename_lower = csv_file.name.lower()
                    log_type = None
                    if 'syslog' in filename_lower:
                        log_type = 'syslog'
                    elif 'connectlog' in filename_lower:
                        log_type = 'connectlog'
                    elif 'filexferlog' in filename_lower or 'filexfer' in filename_lower:
                        log_type = 'filexferlog'
                    
                    # Decode file content
                    file_content = csv_file.read()
                    try:
                        text_content = file_content.decode('utf-8')
                    except UnicodeDecodeError:
                        text_content = file_content.decode('utf-8-sig')  # BOM
                    
                    # Parse CSV
                    csv_reader = csv.reader(io.StringIO(text_content))
                    rows = list(csv_reader)
                    
                    if len(rows) < 2:
                        messages.error(request, 'File CSV kh√¥ng h·ª£p l·ªá. C·∫ßn c√≥ √≠t nh·∫•t header v√† 1 d√≤ng d·ªØ li·ªáu.')
                        return redirect('nas_management:nas_logs')
                    
                    # Detect lo·∫°i log t·ª´ content n·∫øu ch∆∞a detect t·ª´ filename
                    if not log_type:
                        first_row = rows[0] if rows else []
                        if first_row and len(first_row) == 1:
                            if first_row[0] == 'System':
                                log_type = 'syslog'
                            elif first_row[0] == 'Connection':
                                log_type = 'connectlog'
                            elif first_row[0] == 'File Transfer':
                                log_type = 'filexferlog'
                    
                    # N·∫øu v·∫´n ch∆∞a detect ƒë∆∞·ª£c, th·ª≠ t·ª´ header
                    if not log_type:
                        for i in range(min(3, len(rows))):
                            if rows[i] and len(rows[i]) >= 2:
                                header_lower = ' '.join(rows[i]).lower()
                                if 'ip address' in header_lower and 'file' in header_lower:
                                    log_type = 'filexferlog'
                                    break
                                elif 'level' in header_lower and 'log' in header_lower:
                                    # C√≥ th·ªÉ l√† syslog ho·∫∑c connectlog
                                    if i > 0 and rows[i-1] and len(rows[i-1]) == 1:
                                        if rows[i-1][0] == 'System':
                                            log_type = 'syslog'
                                        elif rows[i-1][0] == 'Connection':
                                            log_type = 'connectlog'
                                    else:
                                        log_type = 'syslog'  # Default
                                    break
                    
                    if not log_type:
                        messages.error(request, 'Kh√¥ng th·ªÉ x√°c ƒë·ªãnh lo·∫°i log. Vui l√≤ng ƒë·∫∑t t√™n file ch·ª©a: syslog, connectlog, ho·∫∑c filexferlog')
                        return redirect('nas_management:nas_logs')
                    
                    # T√≠nh to√°n kho·∫£ng th·ªùi gian: th√°ng hi·ªán t·∫°i v√† th√°ng tr∆∞·ªõc
                    now = timezone.now()
                    current_month_start = datetime(now.year, now.month, 1)
                    if now.month == 1:
                        previous_month_start = datetime(now.year - 1, 12, 1)
                    else:
                        previous_month_start = datetime(now.year, now.month - 1, 1)
                    
                    # ƒê·∫£m b·∫£o timezone aware
                    if timezone.is_naive(current_month_start):
                        current_month_start = timezone.make_aware(current_month_start)
                    if timezone.is_naive(previous_month_start):
                        previous_month_start = timezone.make_aware(previous_month_start)
                    
                    # L·∫•y timestamp c·ªßa log m·ªõi nh·∫•t trong database cho NAS v√† log_type n√†y
                    last_log = NASLog.objects.filter(nas=nas, log_type=log_type).order_by('-timestamp').first()
                    last_timestamp = last_log.timestamp if last_log else None
                    
                    # Parse theo lo·∫°i log
                    logs_to_create = []  # Danh s√°ch logs ƒë·ªÉ bulk create
                    count = 0
                    errors = []
                    skipped = 0
                    skipped_old = 0  # ƒê·∫øm s·ªë log b·ªã b·ªè qua v√¨ qu√° c≈©
                    skipped_existing = 0  # ƒê·∫øm s·ªë log ƒë√£ t·ªìn t·∫°i (timestamp <= last_timestamp)
                    
                    if log_type in ['syslog', 'connectlog']:
                        # Format: Level,Log,Time,User,Event
                        start_row = 0
                        if rows[0] and len(rows[0]) == 1 and rows[0][0] in ['System', 'Connection']:
                            start_row = 1
                        
                        header_row = None
                        for i in range(start_row, min(start_row + 3, len(rows))):
                            if len(rows[i]) >= 5:
                                header_row = i
                                break
                        
                        if header_row is None:
                            messages.error(request, f'Kh√¥ng t√¨m th·∫•y header trong file CSV {log_type}. Format c·∫ßn: Level,Log,Time,User,Event')
                            return redirect('nas_management:nas_logs')
                        
                        for row_idx in range(header_row + 1, len(rows)):
                            if len(rows[row_idx]) < 5:
                                continue
                            
                            try:
                                level_str = rows[row_idx][0].strip() if len(rows[row_idx]) > 0 else 'Info'
                                category = rows[row_idx][1].strip() if len(rows[row_idx]) > 1 else (log_type.capitalize())
                                time_str = rows[row_idx][2].strip() if len(rows[row_idx]) > 2 else ''
                                user = rows[row_idx][3].strip() if len(rows[row_idx]) > 3 else ''
                                event = rows[row_idx][4].strip() if len(rows[row_idx]) > 4 else ''
                                
                                # Validate message
                                if not event or len(event.strip()) < 5:
                                    skipped += 1
                                    continue
                                
                                # Normalize level
                                level = level_str.lower()
                                if level not in ['info', 'warning', 'error', 'critical']:
                                    if 'error' in level_str.lower() or 'failed' in level_str.lower():
                                        level = 'error'
                                    elif 'warn' in level_str.lower():
                                        level = 'warning'
                                    else:
                                        level = 'info'
                                
                                # Parse timestamp
                                timestamp = None
                                if time_str:
                                    try:
                                        timestamp = datetime.strptime(time_str, '%Y/%m/%d %H:%M:%S')
                                    except ValueError:
                                        try:
                                            timestamp = datetime.strptime(time_str, '%Y-%m-%d %H:%M:%S')
                                        except ValueError:
                                            timestamp = timezone.now()
                                else:
                                    timestamp = timezone.now()
                                
                                if timezone.is_naive(timestamp):
                                    timestamp = timezone.make_aware(timestamp)
                                
                                # Ch·ªâ l·∫•y log c·ªßa th√°ng hi·ªán t·∫°i v√† th√°ng tr∆∞·ªõc
                                if timestamp < previous_month_start:
                                    skipped_old += 1
                                    continue
                                
                                # Ch·ªâ l·∫•y log m·ªõi h∆°n log cu·ªëi c√πng trong database
                                if last_timestamp and timestamp <= last_timestamp:
                                    skipped_existing += 1
                                    continue
                                
                                # Th√™m v√†o danh s√°ch ƒë·ªÉ bulk create
                                message_short = event[:500]
                                logs_to_create.append(
                                    NASLog(
                                        nas=nas,
                                        log_type=log_type,
                                        timestamp=timestamp,
                                        message=message_short,
                                        level=level,
                                        category=category[:100] if category else (log_type.capitalize()),
                                        source=user[:200] if user else 'SYSTEM',
                                    )
                                )
                                count += 1
                                    
                            except Exception as e:
                                errors.append(f"Row {row_idx + 1}: {str(e)}")
                                continue
                    
                    elif log_type == 'filexferlog':
                        # Format: Log,Time,IP address,User,Event,File/Folder,File size,File name
                        header_row = None
                        for i in range(min(3, len(rows))):
                            if rows[i] and len(rows[i]) >= 8:
                                header_lower = ' '.join(rows[i]).lower()
                                if 'ip address' in header_lower and 'file' in header_lower:
                                    header_row = i
                                    break
                        
                        if header_row is None:
                            messages.error(request, 'Kh√¥ng t√¨m th·∫•y header trong file filexferlog. Format c·∫ßn: Log,Time,IP address,User,Event,File/Folder,File size,File name')
                            return redirect('nas_management:nas_logs')
                        
                        for row_idx in range(header_row + 1, len(rows)):
                            if len(rows[row_idx]) < 8:
                                continue
                            
                            try:
                                log_protocol = rows[row_idx][0].strip() if len(rows[row_idx]) > 0 else 'SMB'
                                time_str = rows[row_idx][1].strip() if len(rows[row_idx]) > 1 else ''
                                ip_address = rows[row_idx][2].strip() if len(rows[row_idx]) > 2 else ''
                                user = rows[row_idx][3].strip() if len(rows[row_idx]) > 3 else ''
                                operation = rows[row_idx][4].strip() if len(rows[row_idx]) > 4 else ''
                                file_type = rows[row_idx][5].strip() if len(rows[row_idx]) > 5 else ''
                                file_size = rows[row_idx][6].strip() if len(rows[row_idx]) > 6 else ''
                                file_path = rows[row_idx][7].strip() if len(rows[row_idx]) > 7 else ''
                                
                                # Validate
                                if not time_str or not file_path:
                                    skipped += 1
                                    continue
                                
                                # Parse timestamp
                                timestamp = None
                                try:
                                    timestamp = datetime.strptime(time_str, '%Y/%m/%d %H:%M:%S')
                                except ValueError:
                                    try:
                                        timestamp = datetime.strptime(time_str, '%Y-%m-%d %H:%M:%S')
                                    except ValueError:
                                        timestamp = timezone.now()
                                
                                if timezone.is_naive(timestamp):
                                    timestamp = timezone.make_aware(timestamp)
                                
                                # Ch·ªâ l·∫•y log c·ªßa th√°ng hi·ªán t·∫°i v√† th√°ng tr∆∞·ªõc
                                if timestamp < previous_month_start:
                                    skipped_old += 1
                                    continue
                                
                                # Ch·ªâ l·∫•y log m·ªõi h∆°n log cu·ªëi c√πng trong database
                                if last_timestamp and timestamp <= last_timestamp:
                                    skipped_existing += 1
                                    continue
                                
                                # T·∫°o message t·ª´ c√°c th√¥ng tin
                                message = f"{operation} {file_type}: {file_path}"
                                message_short = message[:500]
                                
                                # Extract file name t·ª´ path
                                file_name = file_path.split('/')[-1] if '/' in file_path else file_path
                                
                                # Th√™m v√†o danh s√°ch ƒë·ªÉ bulk create
                                logs_to_create.append(
                                    NASLog(
                                        nas=nas,
                                        log_type=log_type,
                                        timestamp=timestamp,
                                        message=message_short,
                                        level='info',
                                        category=log_protocol,
                                        source=user[:200] if user else '',
                                        ip_address=ip_address if ip_address else None,
                                        operation=operation[:50] if operation else '',
                                        file_path=file_path[:1000] if file_path else '',
                                        file_size=file_size[:100] if file_size else '',
                                        file_name=file_name[:500] if file_name else '',
                                    )
                                )
                                count += 1
                                    
                            except Exception as e:
                                errors.append(f"Row {row_idx + 1}: {str(e)}")
                                continue
                    
                    # Bulk create t·∫•t c·∫£ logs (ch·ªâ insert, kh√¥ng check duplicate)
                    if logs_to_create:
                        try:
                            # Chia nh·ªè th√†nh batch 1000 ƒë·ªÉ tr√°nh l·ªói memory
                            batch_size = 1000
                            for i in range(0, len(logs_to_create), batch_size):
                                batch = logs_to_create[i:i + batch_size]
                                NASLog.objects.bulk_create(batch, ignore_conflicts=True)
                        except Exception as e:
                            import logging
                            logger = logging.getLogger('nas_management')
                            logger.error(f"Error bulk creating logs: {str(e)}")
                            messages.error(request, f'L·ªói khi l∆∞u logs: {str(e)}')
                            return redirect('nas_management:nas_logs')
                    
                    # Th√¥ng b√°o k·∫øt qu·∫£
                    log_type_display = dict(NASLog.LOG_TYPE_CHOICES).get(log_type, log_type)
                    if count > 0:
                        msg = f'ƒê√£ import {count} {log_type_display} v√†o {nas.name}'
                        if skipped_existing > 0:
                            msg += f' ({skipped_existing} log ƒë√£ t·ªìn t·∫°i ƒë√£ b·ªè qua)'
                        messages.success(request, msg)
                        if skipped > 0:
                            messages.info(request, f'ƒê√£ b·ªè qua {skipped} log kh√¥ng h·ª£p l·ªá')
                        if skipped_old > 0:
                            messages.info(request, f'ƒê√£ b·ªè qua {skipped_old} log c≈© (ch·ªâ import th√°ng hi·ªán t·∫°i v√† th√°ng tr∆∞·ªõc)')
                        if errors:
                            messages.warning(request, f'C√≥ {len(errors)} l·ªói khi x·ª≠ l√Ω. ƒê√£ import ƒë∆∞·ª£c {count} log.')
                    else:
                        if skipped_existing > 0:
                            messages.info(request, f'T·∫•t c·∫£ {skipped_existing} b·∫£n ghi ƒë√£ t·ªìn t·∫°i trong database (kh√¥ng c√≥ log m·ªõi).')
                        elif skipped_old > 0:
                            messages.warning(request, f'T·∫•t c·∫£ logs trong file ƒë·ªÅu c≈© h∆°n th√°ng hi·ªán t·∫°i v√† th√°ng tr∆∞·ªõc. ƒê√£ b·ªè qua {skipped_old} log.')
                        else:
                            messages.warning(request, f'Kh√¥ng th·ªÉ import {log_type_display}. C√≥ th·ªÉ format file kh√¥ng ƒë√∫ng ho·∫∑c kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá.')
                            if errors:
                                messages.error(request, f'L·ªói: {errors[0] if len(errors) == 1 else f"{len(errors)} l·ªói"}')
                else:
                    messages.error(request, 'File ph·∫£i c√≥ ƒë·ªãnh d·∫°ng CSV (.csv)')
            except Exception as e:
                import traceback
                error_detail = traceback.format_exc()
                messages.error(request, f'L·ªói khi ƒë·ªçc file CSV: {str(e)}')
                import logging
                logger = logging.getLogger('nas_management')
                logger.error(f"Error uploading CSV: {error_detail}")
        else:
            messages.error(request, 'Form kh√¥ng h·ª£p l·ªá. Vui l√≤ng ki·ªÉm tra l·∫°i.')
    else:
        form = LogCSVUploadForm()
    
    # Gi·ªØ l·∫°i filter khi redirect
    redirect_url = reverse('nas_management:nas_logs')
    nas_id = request.GET.get('nas_id')
    if nas_id:
        redirect_url += f'?nas_id={nas_id}'
    
    if form.errors:
        context = {
            'form': form,
            'show_upload_modal': True,
        }
        return render(request, 'nas_management/logs.html', context)
    
    return redirect(redirect_url)


@staff_member_required
def clear_all_logs(request):
    """X√≥a t·∫•t c·∫£ logs trong database"""
    if request.method == 'POST':
        try:
            # L·∫•y s·ªë l∆∞·ª£ng logs tr∆∞·ªõc khi x√≥a
            total_count = NASLog.objects.count()
            
            # X√≥a t·∫•t c·∫£ logs
            NASLog.objects.all().delete()
            
            messages.success(request, f'ƒê√£ x√≥a t·∫•t c·∫£ {total_count} logs trong database.')
        except Exception as e:
            messages.error(request, f'L·ªói khi x√≥a logs: {str(e)}')
            import logging
            logger = logging.getLogger('nas_management')
            logger.error(f"Error clearing logs: {str(e)}")
    
    # Redirect v·ªÅ trang logs
    redirect_url = reverse('nas_management:nas_logs')
    nas_id = request.GET.get('nas_id')
    if nas_id:
        redirect_url += f'?nas_id={nas_id}'
    return redirect(redirect_url)


@staff_member_required
def file_manager(request):
    """Qu·∫£n l√Ω file/folder"""
    nas_list = NASConfig.objects.filter(is_active=True)
    
    nas_id = request.GET.get('nas_id')
    path = request.GET.get('path', '/')
    
    selected_nas = None
    files = []
    current_path = path
    
    if nas_id:
        selected_nas = get_object_or_404(NASConfig, id=nas_id, is_active=True)
    elif nas_list.exists():
        selected_nas = nas_list.first()
    
    if selected_nas:
        try:
            with SynologyAPIClient(selected_nas) as client:
                files_data = client.list_files(folder_path=current_path)
                files = files_data
        except SynologyAPIError as e:
            messages.error(request, f"L·ªói: {str(e)}")
        except Exception as e:
            messages.error(request, f"L·ªói: {str(e)}")
    
    context = {
        'nas_list': nas_list,
        'selected_nas': selected_nas,
        'files': files,
        'current_path': current_path,
    }
    return render(request, 'nas_management/file_manager.html', context)


@staff_member_required
@require_http_methods(["POST"])
def upload_file(request, nas_id):
    """Upload file l√™n NAS"""
    nas = get_object_or_404(NASConfig, id=nas_id, is_active=True)
    
    if 'file' not in request.FILES:
        return JsonResponse({'success': False, 'error': 'Kh√¥ng c√≥ file'})
    
    file = request.FILES['file']
    folder_path = request.POST.get('path', '/')
    
    try:
        with SynologyAPIClient(nas) as client:
            file_content = file.read()
            success = client.upload_file(folder_path, file_content)
            
            if success:
                # Ghi log
                FileOperation.objects.create(
                    nas=nas,
                    user=request.user,
                    operation='upload',
                    file_path=f"{folder_path}/{file.name}",
                    file_size=file.size,
                    is_success=True,
                    ip_address=request.META.get('REMOTE_ADDR'),
                )
                
                return JsonResponse({'success': True, 'message': 'Upload th√†nh c√¥ng'})
            else:
                return JsonResponse({'success': False, 'error': 'Upload th·∫•t b·∫°i'})
                
    except SynologyAPIError as e:
        FileOperation.objects.create(
            nas=nas,
            user=request.user,
            operation='upload',
            file_path=f"{folder_path}/{file.name}",
            file_size=file.size,
            is_success=False,
            error_message=str(e),
            ip_address=request.META.get('REMOTE_ADDR'),
        )
        return JsonResponse({'success': False, 'error': str(e)})
    except Exception as e:
        return JsonResponse({'success': False, 'error': str(e)})


@staff_member_required
def download_file(request, nas_id):
    """Download file t·ª´ NAS"""
    nas = get_object_or_404(NASConfig, id=nas_id, is_active=True)
    file_path = request.GET.get('path')
    
    if not file_path:
        messages.error(request, 'Kh√¥ng c√≥ ƒë∆∞·ªùng d·∫´n file')
        return redirect('nas_management:file_manager')
    
    try:
        with SynologyAPIClient(nas) as client:
            file_content = client.download_file(file_path)
            
            # Ghi log
            FileOperation.objects.create(
                nas=nas,
                user=request.user,
                operation='download',
                file_path=file_path,
                file_size=len(file_content),
                is_success=True,
                ip_address=request.META.get('REMOTE_ADDR'),
            )
            
            # Tr·∫£ v·ªÅ file
            import os
            filename = os.path.basename(file_path)
            response = HttpResponse(file_content, content_type='application/octet-stream')
            response['Content-Disposition'] = f'attachment; filename="{filename}"'
            return response
            
    except SynologyAPIError as e:
        FileOperation.objects.create(
            nas=nas,
            user=request.user,
            operation='download',
            file_path=file_path,
            is_success=False,
            error_message=str(e),
            ip_address=request.META.get('REMOTE_ADDR'),
        )
        messages.error(request, f"L·ªói: {str(e)}")
        return redirect('nas_management:file_manager')
    except Exception as e:
        messages.error(request, f"L·ªói: {str(e)}")
        return redirect('nas_management:file_manager')


@staff_member_required
@require_http_methods(["POST"])
def create_folder(request, nas_id):
    """T·∫°o folder m·ªõi"""
    nas = get_object_or_404(NASConfig, id=nas_id, is_active=True)
    
    folder_path = request.POST.get('path', '/')
    folder_name = request.POST.get('name', '').strip()
    
    if not folder_name:
        return JsonResponse({'success': False, 'error': 'T√™n folder kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng'})
    
    try:
        with SynologyAPIClient(nas) as client:
            success = client.create_folder(folder_path, folder_name)
            
            if success:
                FileOperation.objects.create(
                    nas=nas,
                    user=request.user,
                    operation='create_folder',
                    file_path=f"{folder_path}/{folder_name}",
                    is_success=True,
                    ip_address=request.META.get('REMOTE_ADDR'),
                )
                return JsonResponse({'success': True, 'message': 'T·∫°o folder th√†nh c√¥ng'})
            else:
                return JsonResponse({'success': False, 'error': 'T·∫°o folder th·∫•t b·∫°i'})
                
    except SynologyAPIError as e:
        return JsonResponse({'success': False, 'error': str(e)})
    except Exception as e:
        return JsonResponse({'success': False, 'error': str(e)})


@staff_member_required
@require_http_methods(["POST"])
def delete_file(request, nas_id):
    """X√≥a file/folder"""
    nas = get_object_or_404(NASConfig, id=nas_id, is_active=True)
    
    file_path = request.POST.get('path')
    
    if not file_path:
        return JsonResponse({'success': False, 'error': 'Kh√¥ng c√≥ ƒë∆∞·ªùng d·∫´n file'})
    
    try:
        with SynologyAPIClient(nas) as client:
            success = client.delete_file(file_path)
            
            if success:
                FileOperation.objects.create(
                    nas=nas,
                    user=request.user,
                    operation='delete',
                    file_path=file_path,
                    is_success=True,
                    ip_address=request.META.get('REMOTE_ADDR'),
                )
                return JsonResponse({'success': True, 'message': 'X√≥a th√†nh c√¥ng'})
            else:
                return JsonResponse({'success': False, 'error': 'X√≥a th·∫•t b·∫°i'})
                
    except SynologyAPIError as e:
        return JsonResponse({'success': False, 'error': str(e)})
    except Exception as e:
        return JsonResponse({'success': False, 'error': str(e)})


@staff_member_required
def file_operations(request):
    """L·ªãch s·ª≠ thao t√°c file"""
    nas_list = NASConfig.objects.filter(is_active=True)
    
    nas_id = request.GET.get('nas_id')
    operation = request.GET.get('operation')
    user_id = request.GET.get('user_id')
    
    operations = FileOperation.objects.all()
    
    if nas_id:
        operations = operations.filter(nas_id=nas_id)
    
    if operation:
        operations = operations.filter(operation=operation)
    
    if user_id:
        operations = operations.filter(user_id=user_id)
    
    # Ph√¢n trang
    paginator = Paginator(operations.order_by('-timestamp'), 50)
    page_number = request.GET.get('page')
    page_obj = paginator.get_page(page_number)
    
    context = {
        'nas_list': nas_list,
        'page_obj': page_obj,
        'operations': page_obj,
        'selected_nas_id': nas_id,
        'operation_filter': operation,
        'user_id_filter': user_id,
    }
    return render(request, 'nas_management/file_operations.html', context)
